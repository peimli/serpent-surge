#!/bin/bash
set -euo pipefail

{% set _ep    = rds_endpoint.value if rds_endpoint is mapping else rds_endpoint %}
{% set _user  = db_user.value       if db_user       is mapping else db_user %}
{% set _pass  = db_password.value   if db_password   is mapping else db_password %}
{% set _name  = db_name.value       if db_name       is mapping else db_name %}
{% set _bucket= s3_bucket_name.value      %}
{% set _table = table_name.value if table_name is defined else 'scores' %}

BACKUP_BASE="/var/backups/score"
DUMPS_DIR="$BACKUP_BASE/dumps"
ARCHIVES_DIR="$BACKUP_BASE/archives"

DB_USER="{{ _user }}"
DB_PASS="{{ _pass }}"
DB_NAME="{{ _name }}"
RDS_ENDPOINT="{{ _ep }}"
TABLE_NAME="{{ _table }}"
S3_BUCKET="{{ _bucket }}"

log() { echo "[$(date '+%Y-%m-%d %H:%M:%S')] $*"; }

parse_endpoint() {
  local ep="$1"
  DB_HOST="$ep"
  DB_PORT="3306"
  if [[ "$ep" == *:* ]]; then
    DB_HOST="${ep%%:*}"
    DB_PORT="${ep##*:}"
  fi
}

usage() {
  cat <<EOF
Usage: $0 [--run] [--archive-now] [--list] [--help]
  --run           Napi dump; minden 3. napon (vagy FORCE_ARCHIVE=1 eset√©n) arch√≠v + S3
  --archive-now   Azonnali dump + arch√≠v + S3 (tesztel√©shez)
  --list          Ment√©sek list√°z√°sa
  --help          S√∫g√≥
EOF
}

list_backups() {
  printf "%-8s %-12s %s\n" "TYPE" "DATE" "SIZE(KB)"
  if compgen -G "$DUMPS_DIR/*.sql.gz" >/dev/null; then
    for f in $(ls -1t "$DUMPS_DIR"/*.sql.gz 2>/dev/null); do
      printf "%-8s %-12s %s\n" "DUMP" "$(date -r "$f" '+%Y-%m-%d')" "$(du -k "$f" | cut -f1)"
    done
  fi
  if compgen -G "$ARCHIVES_DIR/*.tar.gz" >/dev/null; then
    for f in $(ls -1t "$ARCHIVES_DIR"/*.tar.gz 2>/dev/null); do
      printf "%-8s %-12s %s\n" "ARCHIVE" "$(date -r "$f" '+%Y-%m-%d')" "$(du -k "$f" | cut -f1)"
    done
  fi
}

run_backup() {
  mkdir -p "$DUMPS_DIR" "$ARCHIVES_DIR"

  parse_endpoint "$RDS_ENDPOINT"
  local today dump_file day_num
  today="$(date +%F)"
  dump_file="$DUMPS_DIR/${today}.sql.gz"
  day_num="$(date +%d)"

  log "üîÑ Starting DB backup (host=$DB_HOST port=$DB_PORT db=$DB_NAME table=$TABLE_NAME)..."

  if ! mysql --ssl-mode=REQUIRED -h "$DB_HOST" -P "$DB_PORT" -u "$DB_USER" -p"$DB_PASS" \
      -e "SELECT 1 FROM information_schema.tables WHERE table_schema='${DB_NAME}' AND table_name='${TABLE_NAME}'" -N >/dev/null 2>&1; then
    log "‚Ñπ Table '${TABLE_NAME}' not found in DB '${DB_NAME}'. Skipping backup."
    return 0
  fi

  if ! mysqldump --ssl-mode=REQUIRED --single-transaction --set-gtid-purged=OFF --skip-lock-tables \
      -h "$DB_HOST" -P "$DB_PORT" -u "$DB_USER" -p"$DB_PASS" "$DB_NAME" "$TABLE_NAME" \
      | gzip > "$dump_file"; then
    log "‚ùå Backup failed"
    return 1
  fi
  log "‚úÖ Dump saved: $dump_file"

  local do_archive=""
  if (( day_num % 3 == 0 )) || [[ "${FORCE_ARCHIVE:-0}" = "1" ]]; then
    do_archive="1"
  fi

  if [[ -n "$do_archive" ]]; then
    local archive_file cnt
    archive_file="$ARCHIVES_DIR/${today}_backup.tar.gz"
    tar -czf "$archive_file" -C "$DUMPS_DIR" "${today}.sql.gz"
    log "üì¶ Archive created: $archive_file"

    cnt=$(ls -1t "$ARCHIVES_DIR"/*.tar.gz 2>/dev/null | wc -l || true)
    if (( cnt > 3 )); then
      ls -1t "$ARCHIVES_DIR"/*.tar.gz | tail -n +4 | while read -r old; do
        log "üóë Removing old archive: $old"
        rm -f -- "$old"
      done
    fi

    if command -v aws >/dev/null 2>&1 && aws sts get-caller-identity >/dev/null 2>&1; then
      if aws s3 cp "$archive_file" "s3://$S3_BUCKET/" --sse AES256; then
        log "‚òÅ Uploaded to S3: s3://$S3_BUCKET/$(basename "$archive_file")"
      else
        log "‚ö† S3 upload failed; continuing."
      fi
    else
      log "‚ö† No AWS credentials; skipping S3 upload."
    fi
  else
    log "‚è© Not an archive day; skipping S3 upload."
  fi
}

case "${1:---run}" in
  --help|-h) usage ;;
  --list|-l) list_backups ;;
  --run|-r|"")
    run_backup
    ;;
  --archive-now)
    FORCE_ARCHIVE=1 run_backup
    ;;
  *)
    usage; exit 1 ;;
esac

